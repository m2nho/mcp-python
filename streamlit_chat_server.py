import streamlit as st
import asyncio
import os
import boto3
import logging
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_aws import ChatBedrock
from langchain.schema.messages import HumanMessage, SystemMessage, ToolMessage

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AWS ì „ë¬¸ ì±„íŒ… ì„œë²„",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– AWS ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸")
st.markdown("AWS CLI ëª…ë ¹ì–´ì™€ ê³µì‹ ë¬¸ì„œë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "cli_messages" not in st.session_state:
    st.session_state.cli_messages = []
if "doc_messages" not in st.session_state:
    st.session_state.doc_messages = []
if "role_arn" not in st.session_state:
    st.session_state.role_arn = ""

# íƒ­ ìƒì„±
tab1, tab2 = st.tabs(["ğŸ’» AWS CLI", "ğŸ“š AWS ë¬¸ì„œ"])
async def invoke_cli_agent(user_input: str):
    """MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ í˜¸ì¶œ"""
    # MCP Client ì´ˆê¸°í™”
    env_vars = {'AWS_REGION': 'ap-northeast-2'}
    
    # Assume Role ì²˜ë¦¬
    if st.session_state.role_arn:
        try:
            sts_client = boto3.client('sts', region_name='ap-northeast-2')
            assumed_role = sts_client.assume_role(
                RoleArn=st.session_state.role_arn,
                RoleSessionName='streamlit-mcp-session'
            )
            credentials = assumed_role['Credentials']
            
            env_vars.update({
                'AWS_ACCESS_KEY_ID': credentials['AccessKeyId'],
                'AWS_SECRET_ACCESS_KEY': credentials['SecretAccessKey'],
                'AWS_SESSION_TOKEN': credentials['SessionToken']
            })
            logger.info(f"Successfully assumed role: {st.session_state.role_arn}")
        except Exception as e:
            logger.error(f"Failed to assume role: {e}")
            st.error(f"Role assume ì‹¤íŒ¨: {str(e)}")
            return "Role assumeì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    mcp_client = MultiServerMCPClient({
        'aws_api': {
            'transport': 'stdio',
            'command': 'uvx',
            'args': ['awslabs.aws-api-mcp-server@latest'],
            'env': env_vars
        }
    })
    
    tools = await mcp_client.get_tools()
    logger.info(f"Available tools: {[tool.name for tool in tools]}")
    logger.info(f"Total tools loaded: {len(tools)}")
    
    # Bedrock í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì›ë˜ ìê²© ì¦ëª… ì‚¬ìš©)
    bedrock_runtime = boto3.client('bedrock-runtime', region_name='ap-northeast-2')
    
    chat_model = ChatBedrock(
        client=bedrock_runtime,
        model_id='apac.anthropic.claude-3-5-sonnet-20241022-v2:0',
        model_kwargs={'temperature': 0.3, 'max_tokens': 4096}
    )
    
    model = chat_model.bind_tools(tools)
    
    messages = [
        SystemMessage(content="AWS ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ call_aws ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³ , ê²°ê³¼ë¥¼ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”."),
        HumanMessage(content=user_input)
    ]
    logger.info(f"Sending messages to model: {len(messages)} messages")
    
    response = await model.ainvoke(messages)
    logger.info(f"Initial response: {response}")
    
    # ë„êµ¬ ì‹¤í–‰
    if hasattr(response, 'tool_calls') and response.tool_calls:
        logger.info(f"Tool calls detected: {len(response.tool_calls)}")
        messages.append(response)
        
        for tool_call in response.tool_calls:
            tool_name = tool_call['name']
            tool_args = tool_call['args']
            logger.info(f"Executing tool: {tool_name} with args: {tool_args}")
            
            for tool in tools:
                if tool.name == tool_name:
                    result = await tool.ainvoke(tool_args)
                    logger.info(f"Tool result: {str(result)}")
                    messages.append(ToolMessage(
                        content=str(result),
                        tool_call_id=tool_call['id'],
                        name=tool_name
                    ))
                    break
        
        final_response = await model.ainvoke(messages)
        logger.info(f"Final response content: {final_response.content}")
        logger.info(f"Final response type: {type(final_response)}")
        if hasattr(final_response, 'content') and final_response.content:
            return final_response.content
        else:
            return "ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    else:
        logger.info("No tool calls detected")
        return response.content

async def invoke_doc_agent(user_input: str):
    """ë¬¸ì„œ ì „ìš© MCP ì—ì´ì „íŠ¸"""
    mcp_client = MultiServerMCPClient({
        'documentation': {
            'transport': 'stdio',
            'command': 'uvx',
            'args': ['awslabs.aws-documentation-mcp-server@latest'],
            'env': {'FASTMCP_LOG_LEVEL': 'ERROR'}
        }
    })
    
    tools = await mcp_client.get_tools()
    logger.info(f"Doc tools: {[tool.name for tool in tools]}")
    logger.info(f"Doc total tools loaded: {len(tools)}")
    
    # Bedrock í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì›ë˜ ìê²© ì¦ëª… ì‚¬ìš©)
    bedrock_runtime = boto3.client('bedrock-runtime', region_name='ap-northeast-2')
        
    chat_model = ChatBedrock(
        client=bedrock_runtime,
        model_id='apac.anthropic.claude-3-5-sonnet-20241022-v2:0',
        model_kwargs={
            'temperature': 0.1,
            'max_tokens': 4096,
            'tool_choice': {'type': 'auto'}
        }
    )
    
    model = chat_model.bind_tools(tools)
    
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ AWS ë¬¸ì„œ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:\n1. search_documentation ë„êµ¬ë¡œ ë¬¸ì„œ ê²€ìƒ‰\n2. ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ read_documentation ë„êµ¬ë¡œ ìƒì„¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°\n3. ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ ë‹µë³€\n\nì¤‘ìš”: ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:\n\n## ë‹µë³€\n(ì‹¤ì œ ë¬¸ì„œ ë‚´ìš© ê¸°ë°˜ ë‹µë³€)\n\n## ì°¸ê³  ë¬¸ì„œ\n- [ë¬¸ì„œì œëª©](URL)\n- [ë¬¸ì„œì œëª©](URL)\n\nì°¸ê³  ë¬¸ì„œ ì„¹ì…˜ì„ ì ˆëŒ€ ë¹ ëœ¨ë¦¬ì§€ ë§ˆì„¸ìš”!"),
        HumanMessage(content=f"ì§ˆë¬¸: {user_input}\n\ní•„ìˆ˜ ì‘ì—…:\n1. search_documentation ë„êµ¬ë¡œ ë¬¸ì„œ ê²€ìƒ‰\n2. ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ URLì„ read_documentation ë„êµ¬ë¡œ ìƒì„¸ ë‚´ìš© ì½ê¸°\n3. ì½ì€ ë‚´ìš©ìœ¼ë¡œë§Œ ë‹µë³€ ì‘ì„±\n\në‘ ë„êµ¬ë¥¼ ëª¨ë‘ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤!")
    ]
    logger.info(f"Doc sending messages to model with system prompt")
    
    # ì§„í–‰ ìƒíƒœ í‘œì‹œ
    progress_container = st.container()
    with progress_container:
        st.markdown("### ğŸ¤– AI ì—ì´ì „íŠ¸ ì‘ì—… ì§„í–‰ìƒí™©")
        progress_bar = st.progress(0)
        status_text = st.empty()
        
    status_text.text("ğŸ’­ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    progress_bar.progress(10)
    
    response = await model.ainvoke(messages)
    
    if hasattr(response, 'tool_calls') and response.tool_calls:
        status_text.text(f"âœ… ë¶„ì„ ì™„ë£Œ! {response.tool_calls[0]['name']} ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        progress_bar.progress(20)
    else:
        status_text.text("âš ï¸ ë„êµ¬ ì—†ì´ ì§ì ‘ ë‹µë³€í•©ë‹ˆë‹¤.")
    
    logger.info(f"Doc initial response: {response}")
    
    # ë„êµ¬ í˜¸ì¶œ ë£¨í”„ - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ ê°€ëŠ¥
    current_response = response
    max_iterations = 5
    iteration = 0
    
    while hasattr(current_response, 'tool_calls') and current_response.tool_calls and iteration < max_iterations:
        iteration += 1
        logger.info(f"Doc tool calls detected (iteration {iteration}): {len(current_response.tool_calls)}")
        messages.append(current_response)
        
        for tool_call in current_response.tool_calls:
            tool_name = tool_call['name']
            tool_args = tool_call['args']
            logger.info(f"Doc executing tool: {tool_name} with args: {tool_args}")
            
            for tool in tools:
                if tool.name == tool_name:
                    result = await tool.ainvoke(tool_args)
                    result_str = str(result)
                    logger.info(f"Doc tool result length: {len(result_str)}")
                    logger.info(f"Doc tool FULL result START: {result_str} :END")
                    
                    # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
                    progress_value = 20 + (iteration * 30)
                    progress_bar.progress(min(progress_value, 80))
                    
                    if tool_name == 'search_documentation':
                        status_text.text("ğŸ” AWS ê³µì‹ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                    elif tool_name == 'read_documentation':
                        status_text.text("ğŸ“„ ì„ íƒëœ ë¬¸ì„œì˜ ìƒì„¸ ë‚´ìš©ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
                    
                    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í‘œì‹œ
                    if tool_name == 'search_documentation':
                        try:
                            import json
                            if isinstance(result, list) and len(result) > 0:
                                doc_count = len(result)
                                status_text.text(f"âœ… {doc_count}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
                                
                                # ê°„ë‹¨í•œ ë¬¸ì„œ ëª©ë¡ í‘œì‹œ
                                with st.expander(f"ğŸ“ ë°œê²¬ëœ {doc_count}ê°œ ë¬¸ì„œ ë³´ê¸°", expanded=False):
                                    for i, item in enumerate(result[:5], 1):
                                        if isinstance(item, str):
                                            item_data = json.loads(item)
                                            st.markdown(f"{i}. **{item_data.get('title', 'Unknown')}**")
                                            st.markdown(f"   ğŸ”— [{item_data.get('url', '#')}]({item_data.get('url', '#')})")
                                            if item_data.get('context'):
                                                st.markdown(f"   ğŸ“ {item_data.get('context')[:100]}...")
                                            st.markdown("---")
                        except:
                            status_text.text("âœ… ë¬¸ì„œ ê²€ìƒ‰ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
                    
                    elif tool_name == 'read_documentation':
                        content_length = len(result_str)
                        status_text.text(f"âœ… ë¬¸ì„œ ë‚´ìš©ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤! ({content_length:,}ë¬¸ì)")
                        
                        # ì½ì€ ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                        if content_length > 1000:
                            with st.expander("ğŸ“„ ì½ì€ ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                                st.markdown(f"**ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:**")
                                st.text_area("", value=result_str[:500] + "...", height=200, disabled=True)
                                st.markdown(f"*ì „ì²´ {content_length:,}ë¬¸ì ì¤‘ 500ë¬¸ì í‘œì‹œ*")
                    messages.append(ToolMessage(
                        content=result_str,
                        tool_call_id=tool_call['id'],
                        name=tool_name
                    ))
                    break
        
        # ë‹¤ìŒ ì‘ë‹µ ë°›ê¸°
        logger.info(f"Doc getting next response from model (iteration {iteration})")
        
        # AI ì‚¬ê³  ë‹¨ê³„ - ê°„ë‹¨í•˜ê²Œ ì§„í–‰ ìƒíƒœë§Œ í‘œì‹œ
        if iteration < max_iterations:
            status_text.text("ğŸ¤– AIê°€ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê³„íší•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            current_response = await model.ainvoke(messages)
            
            if hasattr(current_response, 'tool_calls') and current_response.tool_calls:
                next_tool = current_response.tool_calls[0]['name']
                if next_tool == 'read_documentation':
                    status_text.text("ğŸ“„ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
                else:
                    status_text.text(f"âœ… ë‹¤ìŒ ë‹¨ê³„: {next_tool}")
            else:
                status_text.text("âœ… ëª¨ë“  ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ! ë‹µë³€ì„ ì‘ì„±í•©ë‹ˆë‹¤.")
                progress_bar.progress(90)
        else:
            current_response = await model.ainvoke(messages)
        
        logger.info(f"Doc response object: {current_response}")
    
    # ìµœì¢… ë‹µë³€ ì™„ë£Œ
    progress_bar.progress(100)
    if current_response.content:
        status_text.text("âœ… ë‹µë³€ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        # ì§„í–‰ ìƒíƒœ ìˆ¨ê¸°ê¸° (ì„ íƒì‚¬í•­)
        # progress_container.empty()
    else:
        status_text.text("âŒ ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        st.error("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    
    logger.info(f"Doc final response length: {len(current_response.content)}")
    logger.info(f"Doc final response preview: {current_response.content[:200]}...")
    return current_response.content



def run_async_agent(user_input: str, agent_type: str):
    """ë¹„ë™ê¸° ì—ì´ì „íŠ¸ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰"""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        if agent_type == 'cli':
            return loop.run_until_complete(invoke_cli_agent(user_input))
        else:
            return loop.run_until_complete(invoke_doc_agent(user_input))
    except Exception as e:
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    finally:
        loop.close()

# AWS CLI íƒ­
with tab1:
    st.markdown("### ğŸ’» AWS CLI ëª…ë ¹ì–´ ì‹¤í–‰")
    st.markdown("AWS CLI ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ AWS ë¦¬ì†ŒìŠ¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
    
    # CLI ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.cli_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # CLI ì‚¬ìš©ì ì…ë ¥
    if cli_prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”... (AWS CLI)", key="cli_input"):
        st.session_state.cli_messages.append({"role": "user", "content": cli_prompt})
        with st.chat_message("user"):
            st.markdown(cli_prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                try:
                    response = run_async_agent(cli_prompt, 'cli')
                    st.markdown(response)
                    st.session_state.cli_messages.append({"role": "assistant", "content": response})
                except Exception as e:
                    error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    st.error(error_msg)
                    st.session_state.cli_messages.append({"role": "assistant", "content": error_msg})

# AWS ë¬¸ì„œ íƒ­
with tab2:
    st.markdown("### ğŸ“š AWS ê³µì‹ ë¬¸ì„œ ê²€ìƒ‰")
    st.markdown("AWS ê³µì‹ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ìƒì„¸ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.")
    
    # ë¬¸ì„œ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.doc_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ë¬¸ì„œ ì‚¬ìš©ì ì…ë ¥
    if doc_prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”... (AWS ë¬¸ì„œ)", key="doc_input"):
        st.session_state.doc_messages.append({"role": "user", "content": doc_prompt})
        with st.chat_message("user"):
            st.markdown(doc_prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                try:
                    response = run_async_agent(doc_prompt, 'doc')
                    st.markdown(response)
                    st.session_state.doc_messages.append({"role": "assistant", "content": response})
                except Exception as e:
                    error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    st.error(error_msg)
                    st.session_state.doc_messages.append({"role": "assistant", "content": error_msg})



# ì‚¬ì´ë“œë°”ì— ì„¤ì • ì˜µì…˜
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # Role ARN ì…ë ¥
    role_arn = st.text_input(
        "AWS Role ARN (ì„ íƒì‚¬í•­)",
        value=st.session_state.role_arn,
        placeholder="arn:aws:iam::123456789012:role/MyRole"
    )
    if role_arn != st.session_state.role_arn:
        st.session_state.role_arn = role_arn
        st.rerun()
    
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (CLI)"):
        st.session_state.cli_messages = []
        st.rerun()
    
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (ë¬¸ì„œ)"):
        st.session_state.doc_messages = []
        st.rerun()
    
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (íŒŒì¼ì‹œìŠ¤í…œ)"):
        st.session_state.fs_messages = []
        st.rerun()
    
    st.markdown("---")
    st.markdown("### ğŸ“‹ ì •ë³´")
    st.markdown("- **MCP í”„ë¡œí† ì½œ**: í‘œì¤€ MCP ì‚¬ìš©")
    st.markdown("- **MCP ì„œë²„**: AWS API + Documentation + Filesystem")
    st.markdown("- **ëª¨ë¸**: Claude 3.5 Sonnet")
    st.markdown("- **ë¦¬ì „**: ap-northeast-2")
    st.markdown("- **ê¸°ëŠ¥**: AWS CLI + ë¬¸ì„œ ê²€ìƒ‰ + íŒŒì¼ ê´€ë¦¬")
    
    st.markdown("---")
    st.markdown("### ğŸ’¡ CLI ì‚¬ìš© ì˜ˆì‹œ")
    st.markdown("- 'S3 ë²„í‚· ëª©ë¡ ë³´ì—¬ì¤˜'")
    st.markdown("- 'EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ í™•ì¸í•´ì¤˜'")
    st.markdown("- 'Lambda í•¨ìˆ˜ ëª©ë¡ ì•Œë ¤ì¤˜'")
    
    st.markdown("### ğŸ“š ë¬¸ì„œ ì‚¬ìš© ì˜ˆì‹œ")
    st.markdown("- 'S3 ë²„í‚· ìƒì„± ë°©ë²• ë¬¸ì„œ ì°¾ì•„ì¤˜'")
    st.markdown("- 'Lambda í•¨ìˆ˜ ë°°í¬ ê°€ì´ë“œ ê²€ìƒ‰í•´ì¤˜'")
    st.markdown("- 'EC2 ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ë¹„êµ ë¬¸ì„œ ë³´ì—¬ì¤˜'")
    